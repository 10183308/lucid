{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "texture_synth_3d.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "92V70qggi2PX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "id": "VFkohC1Ei4Oj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OLO6LoELi-n_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3D Feature Visualization\n",
        "\n",
        "This notebook uses  [**Lucid**](https://github.com/tensorflow/lucid) to produce feature visualizations on 3D mesh surfaces by using a [Differentiable Image Parameterization](https://distill.pub/2018/differentiable-parameterizations/#section-featureviz-3d). \n",
        "\n",
        "![](https://storage.googleapis.com/tensorflow-lucid/notebooks/texture-synth-3d/header.jpg =768x)\n",
        "\n",
        "\n",
        "This notebook doesn't introduce the abstractions behind lucid; you may wish to also read the [Lucid tutorial](https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/tutorial.ipynb).\n",
        "\n",
        "**Note**: The easiest way to use this tutorial is as a colab notebook, which allows you to dive in with no setup."
      ]
    },
    {
      "metadata": {
        "id": "nJyLC3QMBnmN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install and imports"
      ]
    },
    {
      "metadata": {
        "id": "0tWshQfbTQrN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook uses OpenGL and thus **requires** a GPU, unlikely most of  our notebooks.\n",
        "You can check whether your GPU is available and configured correctly for tensorflow:"
      ]
    },
    {
      "metadata": {
        "id": "mRGegt1QTUvn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "assert tf.test.is_gpu_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uAIffuU04icG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If it isn't, This notebook uses OpenGL and thus **requires** a GPU. If the above assert statement fails, you can always run the notebook on colab and use a free GPU by selecting:\n",
        "\n",
        "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**"
      ]
    },
    {
      "metadata": {
        "id": "IvqB0eO2HA6s",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip -q install lucid==0.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GVN7tg7Gtb_F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import sys\n",
        "from string import Template\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import matplotlib.pylab as pl\n",
        "\n",
        "from IPython.display import clear_output, display, Image, HTML\n",
        "\n",
        "from lucid.misc.gl.glcontext import create_opengl_context\n",
        "import OpenGL.GL as gl\n",
        "\n",
        "from lucid.misc.gl import meshutil\n",
        "from lucid.misc.gl import glrenderer\n",
        "import lucid.misc.io.showing as show\n",
        "from lucid.misc.io import load\n",
        "from lucid.misc.tfutil import create_session\n",
        "\n",
        "from lucid.modelzoo import vision_models\n",
        "from lucid.optvis import objectives\n",
        "from lucid.optvis import param\n",
        "from lucid.optvis import render as lucid_render\n",
        "from lucid.optvis.param.spatial import sample_bilinear"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z8wv3yfwB6Id",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "create_opengl_context()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_hNBOQKlRSYj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can check the installed version of OpenGL:"
      ]
    },
    {
      "metadata": {
        "id": "szRV2Z3QRR6W",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "gl.glGetString(gl.GL_VERSION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wctACiAdMuqH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading 3D model\n",
        "\n",
        "Let's download four 3D models."
      ]
    },
    {
      "metadata": {
        "id": "VKLoXbi-3kjk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp gs://deepdream/article_models.zip . && \\\n",
        " unzip -qo article_models.zip && \\\n",
        " cat article_models/readme.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "spVDEpplUnWv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The 3D models are in the common [obj format](https://en.wikipedia.org/wiki/Wavefront_.obj_file). They also come with textures, let's take a brief look:"
      ]
    },
    {
      "metadata": {
        "id": "RjilA2KcUi21",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls article_models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9wFC0t_a1N-b",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cw-10aL2Ugbi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](file://)\n",
        "\n",
        "Let's ensure they load…"
      ]
    },
    {
      "metadata": {
        "id": "BRxtnlRD1QxK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wAKOzQtU1Pwv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7cNlampQJ_T8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mesh = meshutil.load_obj('article_models/bunny.obj')\n",
        "mesh = meshutil.normalize_mesh(mesh)\n",
        "original_texture = load('article_models/bunny.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-6zKt1tKWMvy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "…and look reasonable. This  shows you how to use our built-in 3d viewer:"
      ]
    },
    {
      "metadata": {
        "id": "7Q4qBazEWVWg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "show.textured_mesh(mesh, original_texture)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PkU00JHTIE4y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Texture Synthesis\n",
        "\n",
        "We describe this process in the [Efﬁcient Texture Optimization through 3D Rendering](https://drafts.distill.pub/differentiable-parameterizations/#section-featureviz-3d). Remember that the main ingredients beside the 3D model we just loaded are:\n",
        "\n",
        "* a way to sample random views of the 3D model\n",
        "* a renderer, which turns the view, model, & texture into a flat image\n",
        "* a model, which we feed that flat image to calculate a loss and gradients with respect to the flat image\n",
        "\n",
        "…and from there we can use our knowledge of which parts of the 3D model were visible in the flat image to backpropagate that gradient through the rendering process and into the learned texture.\n",
        "\n",
        "![](https://storage.googleapis.com/tensorflow-lucid/notebooks/texture-synth-3d/featurevis-3d.svg)"
      ]
    },
    {
      "metadata": {
        "id": "z-ysq_43dgQg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Renderer"
      ]
    },
    {
      "metadata": {
        "id": "mddOtGtpgyiA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We provide a way to sample random views onto a 3D model. You can specify the range of distances, and the resulting views will be centered on the object. The resulting 4x4 matrix is interpreted as a [ModelView matrix](http://www.opengl-tutorial.org/beginners-tutorials/tutorial-3-matrices/#the-view-matrix). "
      ]
    },
    {
      "metadata": {
        "id": "safpt86FhAoZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "random_view = meshutil.sample_view(11.0, 13.0,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xKMijvY7hF5R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's initialize a renderer and take a look on our mesh from the direction of `random_view`."
      ]
    },
    {
      "metadata": {
        "id": "Z4A1_xf90kUX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "renderer = glrenderer.MeshRenderer((512, 512))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O9LqbB4xa72v",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "random_view_image = renderer.render_mesh(modelview=random_view, **mesh)\n",
        "show.image(random_view_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VbKF7lQax5y-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that this image has an alpha channel to separate foreground from background, and the colors red and green encode the UV coordinates—where a pixel in the texture would end up on the model. We will use this information to take the gradient of the flat image coming from our CNN model and translate it back onto the texture we're learning/optimizing."
      ]
    },
    {
      "metadata": {
        "id": "qaUWfxxIdjMJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CNN model\n",
        "\n",
        "We want to synthesize a texture with some property that we can describe in the feature space of our pretrained CNN. For simplicity, we focus on a simple Feature Visualization objective here—but in the follow up notebook we will use a more complex style transfer objective for even more interesting results.\n",
        "\n",
        "Let's start by loading up our CNN model as usual:"
      ]
    },
    {
      "metadata": {
        "id": "aphqLRmZBy5D",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = vision_models.InceptionV1()\n",
        "model.load_graphdef()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jem1Nnsyvr_d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And quickly see a simple 2D image optimized for the same Feature Visualization objective we'll later use to generate the 3D model's texture:"
      ]
    },
    {
      "metadata": {
        "id": "f5yCEPEefDU4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "objective = objectives.channel('mixed4b_pool_reduce_pre_relu', 17)\n",
        "vis = lucid_render.render_vis(model, objective, verbose=False) # (lucid.otvis.render is imported as lucid_render to differentiate it from the 3D renderer)\n",
        "show.image(vis)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "awiWIsOfdkkT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Synthesize the texture"
      ]
    },
    {
      "metadata": {
        "id": "Aqd-AQcjQYhS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sess = create_session()\n",
        "\n",
        "# t_fragments is used to feed rasterized UV coordinates for the current view.\n",
        "# Channels: [U, V, _, Alpha]. Alpha is 1 for pixels covered by the object, and\n",
        "# 0 for background.\n",
        "t_fragments = tf.placeholder(tf.float32, [None, None, 4])\n",
        "t_uv = t_fragments[...,:2]\n",
        "t_alpha = t_fragments[...,3:]\n",
        "\n",
        "t_texture = param.image(1024, fft=True, decorrelate=True)[0]\n",
        "t_frame = sample_bilinear(t_texture, t_uv) * t_alpha\n",
        "\n",
        "model.import_graph(t_frame)\n",
        "\n",
        "\n",
        "def T(layer):\n",
        "  return sess.graph.get_tensor_by_name(\"import/%s:0\"%layer)\n",
        "\n",
        "# obj = objectives.channel('mixed3a_1x1_pre_relu', 1)(T)\n",
        "# obj = objectives.channel('mixed4a_1x1_pre_relu', 26)(T)\n",
        "# obj = objectives.channel('mixed4a_1x1_pre_relu', 11)(T)\n",
        "# obj = objectives.channel('mixed4a_3x3_pre_relu', 27)(T)\n",
        "# obj = objectives.channel('mixed4a_3x3_pre_relu', 174)(T)\n",
        "# obj = objectives.channel('mixed4a_1x1_pre_relu', 179)(T)\n",
        "# obj = objectives.channel('mixed4a_1x1_pre_relu', 190)(T)\n",
        "# obj = objectives.channel('mixed4a_1x1_pre_relu', 5)(T)\n",
        "\n",
        "obj = objectives.channel('mixed4b_pool_reduce_pre_relu', 17)(T)\n",
        "tf.losses.add_loss(-obj)\n",
        "\n",
        "\n",
        "t_lr = tf.constant(0.01)\n",
        "t_loss = tf.losses.get_total_loss()\n",
        "trainer = tf.train.AdamOptimizer(t_lr)\n",
        "train_op = trainer.minimize(t_loss)\n",
        "\n",
        "init_op = tf.global_variables_initializer()\n",
        "init_op.run()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W2VPfEMDxCRH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can sanity check that at least our parameterization fits together by generating the UV map again with the renderer (\"`fragments`\") and then `eval`ing the `t_frame` tensor while feeding the original texture:"
      ]
    },
    {
      "metadata": {
        "id": "TuGggs9RJ5u1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fragments = renderer.render_mesh(modelview=meshutil.sample_view(11.0, 13.0), **mesh)\n",
        "img = t_frame.eval({t_fragments: fragments, t_texture: original_texture})\n",
        "show.images([fragments, img])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vyT12mXfzqac",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looks reasonable! Let's run the actual optimization loop and see if we can generate a texture!"
      ]
    },
    {
      "metadata": {
        "id": "vdd8V9mdCJRS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "loss_log = []\n",
        "init_op.run()\n",
        "\n",
        "for i in range(400):\n",
        "  \n",
        "  # Render mesh UVs with OpenGL\n",
        "  fragments = renderer.render_mesh(modelview=meshutil.sample_view(11.0, 13.0), **mesh)\n",
        "  \n",
        "  # Perform step optimization for the current view\n",
        "  _, loss = sess.run([train_op, t_loss], {t_fragments: fragments, t_lr:0.03})\n",
        "  loss_log.append(loss)\n",
        "  \n",
        "  # Reporting\n",
        "  if i==0 or (i+1)%50 == 0:\n",
        "    clear_output()\n",
        "    last_frame = sess.run(t_frame, {t_fragments: fragments})\n",
        "    show.images([last_frame, fragments], ['current', 'uv'])\n",
        "    \n",
        "  if i==0 or (i+1)%10 == 0:\n",
        "    print(len(loss_log), loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "siNc45GDz8ZM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since this is such a stochastic procedure, it's good to sanity check that we observe the loss going down. Remember the loss only captures how well the final rendered image activates the feature we are optimizing for, while we view the 3D model from a different perspective at each time—so expect high variance."
      ]
    },
    {
      "metadata": {
        "id": "K53nDwFNMMkH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pl.plot(loss_log);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "87MvSdldFOso",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### View the result"
      ]
    },
    {
      "metadata": {
        "id": "5UG6AYJwFOFr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "texture = t_texture.eval()\n",
        "show.textured_mesh(mesh, texture)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bdavL3JF0xcv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can also view the texture we optimized directly:"
      ]
    },
    {
      "metadata": {
        "id": "Nz2pS_FM8XEW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "show.image(texture, 'jpeg')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}