{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "texture_style_3d.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1ivqIrW2zbdNAL-upEVuUwTb4u7rPy4Ci",
          "timestamp": 1517936840805
        }
      ],
      "collapsed_sections": [
        "92V70qggi2PX",
        "308s8x7lrkNE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "92V70qggi2PX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "metadata": {
        "id": "VFkohC1Ei4Oj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GS4kqcEJuy5R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3D Style Transfer\n",
        "\n",
        "This notebook uses  [**Lucid**](https://github.com/tensorflow/lucid) to implement style transfer from a textured 3D model and a style image onto a new texture for the 3D model by using a [Differentiable Image Parameterization](https://distill.pub/2018/differentiable-parameterizations/#section-style-transfer-3d). \n",
        "\n",
        "![](https://storage.googleapis.com/tensorflow-lucid/notebooks/styletransfer-3d/header.jpg =724x)\n",
        "\n",
        "\n",
        "This notebook doesn't introduce the abstractions behind lucid; you may wish to also read the [Lucid tutorial](https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/tutorial.ipynb).\n",
        "\n",
        "**Note**: The easiest way to use this tutorial is as a colab notebook, which allows you to dive in with no setup."
      ]
    },
    {
      "metadata": {
        "id": "GDHbJbsiA8bC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install, Import, Initialize OpenGL, and load a CNN model"
      ]
    },
    {
      "metadata": {
        "id": "0tWshQfbTQrN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook uses OpenGL and thus **requires** a GPU, unlikely most of  our notebooks.\n",
        "You can check whether your GPU is available and configured correctly for tensorflow:"
      ]
    },
    {
      "metadata": {
        "id": "mRGegt1QTUvn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "assert tf.test.is_gpu_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uAIffuU04icG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If the above assert statement fails, you can always run the notebook on colab and use a free GPU by selecting:\n",
        "\n",
        "> **Runtime**   →   **Change runtime type**   →   **Hardware Accelerator: GPU**"
      ]
    },
    {
      "metadata": {
        "id": "QxA8kXBXCuNm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q lucid>=0.2.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GVN7tg7Gtb_F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import sys\n",
        "from string import Template\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import matplotlib.pylab as pl\n",
        "from google.colab import files\n",
        "\n",
        "from IPython.display import clear_output, display, Image, HTML\n",
        "\n",
        "from lucid.misc.gl.glcontext import create_opengl_context\n",
        "import OpenGL.GL as gl\n",
        "\n",
        "from lucid.misc.gl import meshutil\n",
        "from lucid.misc.gl import glrenderer\n",
        "import lucid.misc.io.showing as show\n",
        "import lucid.misc.io as lucid_io\n",
        "from lucid.misc.tfutil import create_session\n",
        "\n",
        "from lucid.modelzoo import vision_models\n",
        "from lucid.optvis import objectives\n",
        "from lucid.optvis import param\n",
        "from lucid.optvis.style import StyleLoss, mean_l1_loss\n",
        "from lucid.optvis.param.spatial import sample_bilinear"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_hNBOQKlRSYj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can check the installed version of OpenGL:"
      ]
    },
    {
      "metadata": {
        "id": "szRV2Z3QRR6W",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "create_opengl_context()\n",
        "gl.glGetString(gl.GL_VERSION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NuzqC939QFDz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "model = vision_models.InceptionV1()\n",
        "model.load_graphdef()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wctACiAdMuqH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading 3D model\n",
        "\n",
        "Let's download some 3D models first. This is similar to the steps in the [3D Feature Visualization notebook](https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/differentiable-parameterizations/texture_synth_3d.ipynb) if you're keen on the details and haven't completed that notebook yet."
      ]
    },
    {
      "metadata": {
        "id": "hA8vzWUyd6iq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "TEXTURE_SIZE = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ygtXMGPq3TBW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!gsutil cp gs://deepdream/article_models.zip . && \\\n",
        " unzip -qo article_models.zip && \\\n",
        " ls -al article_models && \\\n",
        " cat article_models/readme.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oGmBlka73VMh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def prepare_image(fn, size=None):\n",
        "  data = lucid_io.reading.read(fn)\n",
        "  im = PIL.Image.open(io.BytesIO(data)).convert('RGB')\n",
        "  if size:\n",
        "    im = im.resize(size, PIL.Image.ANTIALIAS)\n",
        "  return np.float32(im)/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CAa3iFUuLaVa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "mesh = meshutil.load_obj('article_models/skull.obj')\n",
        "mesh = meshutil.normalize_mesh(mesh)\n",
        "\n",
        "original_texture = prepare_image('article_models/skull.jpg', (TEXTURE_SIZE, TEXTURE_SIZE))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rcWl0kdaH8xi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "style_url = 'https://upload.wikimedia.org/wikipedia/commons/d/db/RIAN_archive_409362_Literaturnaya_Gazeta_article_about_YuriGagarin%2C_first_man_in_space.jpg'\n",
        "style = prepare_image(style_url)\n",
        "show.image(style, 'jpeg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PkU00JHTIE4y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Texture Synthesis"
      ]
    },
    {
      "metadata": {
        "id": "Z4A1_xf90kUX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "renderer = glrenderer.MeshRenderer((512, 512))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cvnsl8DFbPJz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "googlenet_style_layers = [\n",
        "    'conv2d2',\n",
        "    'mixed3a',\n",
        "    'mixed3b',\n",
        "    'mixed4a',\n",
        "    'mixed4b',\n",
        "    'mixed4c',\n",
        "]\n",
        "\n",
        "googlenet_content_layer = 'mixed3b'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Aqd-AQcjQYhS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "content_weight = 100.0\n",
        "# Style Gram matrix weighted average decay coefficient\n",
        "style_decay = 0.95\n",
        "\n",
        "sess = create_session(timeout_sec=0)\n",
        "\n",
        "# t_fragments is used to feed rasterized UV coordinates for the current view.\n",
        "# Channels: [U, V, _, Alpha]. Alpha is 1 for pixels covered by the object, and\n",
        "# 0 for background.\n",
        "t_fragments = tf.placeholder(tf.float32, [None, None, 4])\n",
        "t_uv = t_fragments[...,:2]\n",
        "t_alpha = t_fragments[...,3:]\n",
        "\n",
        "# Texture atlas to optimize\n",
        "t_texture = param.image(TEXTURE_SIZE, fft=True, decorrelate=True)[0]\n",
        "\n",
        "# Variable to store the original mesh texture used to render content views\n",
        "content_var = tf.Variable(tf.zeros([TEXTURE_SIZE, TEXTURE_SIZE, 3]), trainable=False)\n",
        "\n",
        "# Sample current and original textures with provided pixel data\n",
        "t_joined_texture = tf.concat([t_texture, content_var], -1)\n",
        "t_joined_frame = sample_bilinear(t_joined_texture, t_uv) * t_alpha\n",
        "t_frame_current, t_frame_content = t_joined_frame[...,:3], t_joined_frame[...,3:]\n",
        "t_joined_frame = tf.stack([t_frame_current, t_frame_content], 0)\n",
        "\n",
        "# Feeding the rendered frames to the Neural Network\n",
        "t_input = tf.placeholder_with_default(t_joined_frame, [None, None, None, 3])\n",
        "model.import_graph(t_input)\n",
        "\n",
        "# style loss\n",
        "style_layers = [sess.graph.get_tensor_by_name('import/%s:0'%s)[0] for s in googlenet_style_layers]\n",
        "# L1-loss seems to be more stable for GoogleNet\n",
        "# Note that we use style_decay>0 to average style-describing Gram matrices\n",
        "# over the recent viewports. Please refer to StyleLoss for the details.\n",
        "sl = StyleLoss(style_layers, style_decay, loss_func=mean_l1_loss)\n",
        "\n",
        "# content loss\n",
        "content_layer = sess.graph.get_tensor_by_name('import/%s:0'%googlenet_content_layer)\n",
        "content_loss = mean_l1_loss(content_layer[0], content_layer[1]) * content_weight\n",
        "\n",
        "# setup optimization\n",
        "total_loss = content_loss + sl.style_loss\n",
        "t_lr = tf.constant(0.05)\n",
        "trainer = tf.train.AdamOptimizer(t_lr)\n",
        "train_op = trainer.minimize(total_loss)\n",
        "\n",
        "init_op = tf.global_variables_initializer()\n",
        "loss_log = []\n",
        "\n",
        "def reset(style_img, content_texture):\n",
        "  del loss_log[:]\n",
        "  init_op.run()\n",
        "  sl.set_style({t_input: style_img[None,...]})\n",
        "  content_var.load(content_texture)\n",
        "  \n",
        "def run(mesh, step_n=400):\n",
        "  for i in range(step_n):\n",
        "    fragments = renderer.render_mesh(\n",
        "        modelview=meshutil.sample_view(10.0, 12.0),\n",
        "        position=mesh['position'], uv=mesh['uv'],\n",
        "        face=mesh['face'])\n",
        "    _, loss = sess.run([train_op, [content_loss, sl.style_loss]], {t_fragments: fragments})\n",
        "    loss_log.append(loss)\n",
        "    if i==0 or (i+1)%50 == 0:\n",
        "      clear_output()\n",
        "      last_frame, last_content = sess.run([t_frame_current, t_frame_content], {t_fragments: fragments})\n",
        "      show.images([last_frame, last_content], ['current frame', 'content'])\n",
        "    if i==0 or (i+1)%10 == 0:\n",
        "      print(len(loss_log), loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "asDp-dRxCN8O",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "reset(style, original_texture)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vdd8V9mdCJRS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "run(mesh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "74Gm0fXAdVFM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since this is such a stochastic optimization procedure, it's good to sanity check that we observe the loss going down."
      ]
    },
    {
      "metadata": {
        "id": "K53nDwFNMMkH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pl.plot(loss_log);\n",
        "pl.legend(['Content Loss', 'Style Loss'])\n",
        "pl.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "87MvSdldFOso",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Display Result\n",
        "\n",
        "For the models with less complex textures—i.e. all except the bunny model—the content objective can be subtle. For example, in the case of the skull, its easiest to observe that the content loss is effective when viewing the [cranial sutures](https://en.wikipedia.org/wiki/Suture_(anatomy)). You can click and drag the output of the next cell to view the sides and top of the skull model."
      ]
    },
    {
      "metadata": {
        "id": "5UG6AYJwFOFr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "texture = t_texture.eval()\n",
        "show.textured_mesh(mesh, texture)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vQUPeLVwhOAO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can also view the texture we optimized directly:"
      ]
    },
    {
      "metadata": {
        "id": "Nz2pS_FM8XEW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "show.image(texture)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZAB6zjF3hQzN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As an aside for the interested reader: the texture above still shows the original random initialization in the patches that aren't seen during the rendering. Can you think of a way to make these parts black, so the texture compresses better? \n",
        "\n",
        "*Hint: one approach could be to add a loss on the mean of the texture as a whole.* Give it a try!"
      ]
    },
    {
      "metadata": {
        "id": "308s8x7lrkNE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Batch texture generation\n",
        "\n",
        "We are sometimes asked how we generate the data for interactive [Distill](https://distill.pub) articles. Usually the process is not very interesting, so we don't always include it in our notebooks. For the interrested reader, though, here is an example of running colab functions for many different input images.\n",
        "\n",
        "These cells save assets locally on the colab runtime's VM. After running these cells, we use the `google.colab.files` module to download these assets to our development machines."
      ]
    },
    {
      "metadata": {
        "id": "a4AXBajl4XRK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "styles = '''\n",
        "starry  https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/606px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg\n",
        "onwhite https://upload.wikimedia.org/wikipedia/commons/c/c4/Vassily_Kandinsky%2C_1923_-_On_White_II.jpg\n",
        "mosaic  https://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Fernand_L%C3%A9ger_-_Grand_parade_with_red_background_%28mosaic%29_1958_made.jpg/637px-Fernand_L%C3%A9ger_-_Grand_parade_with_red_background_%28mosaic%29_1958_made.jpg\n",
        "points https://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Robert_Delaunay%2C_1906%2C_Portrait_de_Metzinger%2C_oil_on_canvas%2C_55_x_43_cm%2C_DSC08255.jpg/449px-Robert_Delaunay%2C_1906%2C_Portrait_de_Metzinger%2C_oil_on_canvas%2C_55_x_43_cm%2C_DSC08255.jpg\n",
        "scream https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/The_Scream.jpg/471px-The_Scream.jpg\n",
        "noodles https://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Noodles_and_eggs20170520_1035.jpg/526px-Noodles_and_eggs20170520_1035.jpg\n",
        "newspaper https://upload.wikimedia.org/wikipedia/commons/d/db/RIAN_archive_409362_Literaturnaya_Gazeta_article_about_YuriGagarin%2C_first_man_in_space.jpg\n",
        "birds https://canyouseedotca.files.wordpress.com/2016/01/mce-birds.jpg\n",
        "cross https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Cross_stitch_detail.jpg/640px-Cross_stitch_detail.jpg\n",
        "galaxy https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/NGC_4414_%28NASA-med%29.jpg/582px-NGC_4414_%28NASA-med%29.jpg\n",
        "cd https://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/CD_autolev_crop.jpg/480px-CD_autolev_crop.jpg\n",
        "'''.split()\n",
        "styles = list(zip(styles[::2], styles[1::2]))\n",
        "HTML(\" \".join('<a href=\"%s\">%s</a>'%(url, name) for name, url in styles))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pJRQy1wDSbED",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from lucid.misc.io.writing import write\n",
        "\n",
        "\n",
        "def export_mesh(name, mesh):\n",
        "  data_to_save = {\n",
        "      'position': mesh['position'].ravel(), \n",
        "      'uv': mesh['uv'].ravel(), \n",
        "      'face': np.uint32(mesh['face'].ravel())\n",
        "  }\n",
        "  for key, value in data_to_save.items():\n",
        "    data = value.tobytes()\n",
        "    filename = '%s_%s.3d'%(name, key)\n",
        "    write(data, filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7U_jvBZ9r-Ul",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "for mesh_path in Path('article_models/').glob('*.obj'):\n",
        "  mesh_name = mesh_path.stem\n",
        "  print(mesh_name)\n",
        "  \n",
        "  tex_path = mesh_path.with_suffix('.jpg')\n",
        "  if not tex_path.exists():\n",
        "    tex_path = mesh_path.with_suffix('.png')\n",
        "  \n",
        "  mesh = meshutil.load_obj(str(mesh_path))\n",
        "  mesh = meshutil.normalize_mesh(mesh)\n",
        "  original_texture = prepare_image(str(tex_path), (TEXTURE_SIZE, TEXTURE_SIZE))\n",
        "  \n",
        "  export_mesh(mesh_name, mesh)\n",
        "  lucid_io.save(original_texture, mesh_name+'_tex.jpg', quality=90)\n",
        "\n",
        "  for style_name, url in styles:\n",
        "    if style_name[0] == '#':\n",
        "      continue\n",
        "    style_img = prepare_image(url)\n",
        "    reset(style_img, original_texture)\n",
        "    run(mesh, step_n=800)\n",
        "    texture = t_texture.eval()\n",
        "    filename = '%s_tex_%s.jpg'%(mesh_name, style_name)\n",
        "    lucid_io.save(texture, filename, quality=90)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}